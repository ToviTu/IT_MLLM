{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "#notebook_login()\n",
    "API_TOKEN = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dfbeb00c3dd4eeda0324f00a7b25116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", cache_dir=\"/mnt/d/models/\", device_map='auto', torch_dtype=torch.float16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", cache_dir=\"/mnt/d/models/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.datasets import SQUAD_dataset\n",
    "\n",
    "data = SQUAD_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction =  'Suppose you are teaching a first grader. Answer the question according to the provided context and explain to the first grader your method to find the answer without referring back to the context in the form \"Rationale: <reasons> \\n Answer: <answer>\" where <reasons> and <answer> are your response. Make your response as short as possible.\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [52:19<00:00,  1.57s/it] \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import tqdm\n",
    "def prompt_template(context, question):\n",
    "    return instruction + f\"Question: {question}\\n Context: {context}\"\n",
    "\n",
    "results = {}\n",
    "\n",
    "for seed in tqdm.tqdm(range(2000)):\n",
    "    random.seed(seed)\n",
    "    idx = int(random.random() * len(data.train_dataset))\n",
    "    sample = data.train_dataset[idx]\n",
    "    context = sample['context']\n",
    "    id = sample['id']\n",
    "    question = sample['question']\n",
    "    input = prompt_template(context, question)\n",
    "    encoded = tokenizer(input, return_tensors='pt')\n",
    "    output = model.generate(\n",
    "        input_ids = encoded['input_ids'].to(0),\n",
    "        attention_mask = encoded['attention_mask'].to(0, dtype=torch.float16),\n",
    "        )\n",
    "    answer = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    results[id] = answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/mnt/d/datasets/psuedo_dataset.json', 'w') as f:\n",
    "    json.dump(results, f, indent=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flamingo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
