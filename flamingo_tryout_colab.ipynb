{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C2k0MmthXpIa",
    "outputId": "02e15313-fcd7-4819-e43d-da1b6bdf361b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "280a52996b73478198398b54296b4f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import open_flamingo\n",
    "from open_flamingo import create_model_and_transforms\n",
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tovitu/.cache/huggingface/modules/transformers_modules/mosaicml/mpt-1b-redpajama-200b/a0929818043de593a6b4248481e18a4b276f5e1e/attention.py:289: UserWarning: Using `attn_impl: torch`. If your model does not use `alibi` or `prefix_lm` we recommend using `attn_impl: flash` otherwise we recommend using `attn_impl: triton`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using config.init_device='cpu', but you can also use config.init_device=\"meta\" with Composer + FSDP for fast initialization.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mosaicml/mpt-1b-redpajama-200b\", trust_remote_code=True, cache_dir=\"/mnt/d/models/\")\n",
    "model.to(device='cuda:0', dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mosaicml/mpt-1b-redpajama-200b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.datasets import SQUAD_dataset\n",
    "\n",
    "dataset = SQUAD_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = tokenizer(data.val_dataset[0]['context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tovitu/miniconda3/envs/flamingo/lib/python3.10/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/tovitu/miniconda3/envs/flamingo/lib/python3.10/site-packages/transformers/generation/utils.py:1281: UserWarning: Input length of input_ids is 158, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(\n",
    "    input_ids = torch.tensor([token['input_ids']]).to(0),\n",
    "    attention_mask = torch.tensor([token['attention_mask']], dtype=torch.bfloat16).to(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 40/2000 [00:49<40:04,  1.23s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/tovitu/codes/Instruction-tuned-Flamingo-MLLM/flamingo_tryout_colab.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tovitu/codes/Instruction-tuned-Flamingo-MLLM/flamingo_tryout_colab.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m answer_len \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tovitu/codes/Instruction-tuned-Flamingo-MLLM/flamingo_tryout_colab.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# Inference\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tovitu/codes/Instruction-tuned-Flamingo-MLLM/flamingo_tryout_colab.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m output \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tovitu/codes/Instruction-tuned-Flamingo-MLLM/flamingo_tryout_colab.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m     input_ids \u001b[39m=\u001b[39;49m torch\u001b[39m.\u001b[39;49mtensor([text_token[\u001b[39m\"\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m\"\u001b[39;49m]])\u001b[39m.\u001b[39;49mto(device),\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tovitu/codes/Instruction-tuned-Flamingo-MLLM/flamingo_tryout_colab.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m     attention_mask \u001b[39m=\u001b[39;49m torch\u001b[39m.\u001b[39;49mtensor([text_token[\u001b[39m\"\u001b[39;49m\u001b[39mattention_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m]])\u001b[39m.\u001b[39;49mto(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tovitu/codes/Instruction-tuned-Flamingo-MLLM/flamingo_tryout_colab.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m         device\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mbfloat16\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tovitu/codes/Instruction-tuned-Flamingo-MLLM/flamingo_tryout_colab.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m     ),\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tovitu/codes/Instruction-tuned-Flamingo-MLLM/flamingo_tryout_colab.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m     max_new_tokens\u001b[39m=\u001b[39;49manswer_len,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tovitu/codes/Instruction-tuned-Flamingo-MLLM/flamingo_tryout_colab.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m     pad_token_id\u001b[39m=\u001b[39;49m\u001b[39m50277\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tovitu/codes/Instruction-tuned-Flamingo-MLLM/flamingo_tryout_colab.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tovitu/codes/Instruction-tuned-Flamingo-MLLM/flamingo_tryout_colab.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m output \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mdecode(output[\u001b[39m0\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/tovitu/codes/Instruction-tuned-Flamingo-MLLM/flamingo_tryout_colab.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m output \u001b[39m=\u001b[39m output[\u001b[39mlen\u001b[39m(prompt) :]\n",
      "File \u001b[0;32m~/miniconda3/envs/flamingo/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/flamingo/lib/python3.10/site-packages/transformers/generation/utils.py:1673\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1656\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39massisted_decoding(\n\u001b[1;32m   1657\u001b[0m         input_ids,\n\u001b[1;32m   1658\u001b[0m         assistant_model\u001b[39m=\u001b[39massistant_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1669\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1670\u001b[0m     )\n\u001b[1;32m   1671\u001b[0m \u001b[39mif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1672\u001b[0m     \u001b[39m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1673\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgreedy_search(\n\u001b[1;32m   1674\u001b[0m         input_ids,\n\u001b[1;32m   1675\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1676\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   1677\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mpad_token_id,\n\u001b[1;32m   1678\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49meos_token_id,\n\u001b[1;32m   1679\u001b[0m         output_scores\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49moutput_scores,\n\u001b[1;32m   1680\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1681\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1682\u001b[0m         streamer\u001b[39m=\u001b[39;49mstreamer,\n\u001b[1;32m   1683\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1684\u001b[0m     )\n\u001b[1;32m   1686\u001b[0m \u001b[39melif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1687\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m model_kwargs[\u001b[39m\"\u001b[39m\u001b[39muse_cache\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda3/envs/flamingo/lib/python3.10/site-packages/transformers/generation/utils.py:2518\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2515\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   2517\u001b[0m \u001b[39m# prepare model inputs\u001b[39;00m\n\u001b[0;32m-> 2518\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs)\n\u001b[1;32m   2520\u001b[0m \u001b[39m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m   2521\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(\n\u001b[1;32m   2522\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_inputs,\n\u001b[1;32m   2523\u001b[0m     return_dict\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   2524\u001b[0m     output_attentions\u001b[39m=\u001b[39moutput_attentions,\n\u001b[1;32m   2525\u001b[0m     output_hidden_states\u001b[39m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   2526\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/mosaicml/mpt-1b-redpajama-200b/a0929818043de593a6b4248481e18a4b276f5e1e/mosaic_gpt.py:403\u001b[0m, in \u001b[0;36mMosaicGPT.prepare_inputs_for_generation\u001b[0;34m(self, input_ids, past_key_values, inputs_embeds, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    400\u001b[0m         \u001b[39m'\u001b[39m\u001b[39minputs_embeds is not implemented for MosaicGPT yet\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    402\u001b[0m attention_mask \u001b[39m=\u001b[39m kwargs[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mbool()\n\u001b[0;32m--> 403\u001b[0m \u001b[39mif\u001b[39;00m attention_mask[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msum() \u001b[39m!=\u001b[39m attention_mask\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m    404\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    405\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mMosaicGPT does not support generation with right padding.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    407\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattn_uses_sequence_id \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import os\n",
    "import json\n",
    "\n",
    "output_dir = '/mnt/d/datasets/'\n",
    "\n",
    "device = 0\n",
    "precision = torch.bfloat16\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "counter = 0\n",
    "for idx in tqdm.tqdm(range(2000)):\n",
    "    data = dataset.val_dataset[idx]\n",
    "\n",
    "    context = data[\"context\"]\n",
    "    question = data[\"question\"]\n",
    "\n",
    "    context_text = dataset.make_in_context(dataset.train_dataset, shots=4)\n",
    "\n",
    "    # Encode text\n",
    "    prompt = context_text +  dataset.qa_prompt(context, question)\n",
    "    text_token = tokenizer(prompt)\n",
    "\n",
    "    answer_len = max(\n",
    "        [len(answer.split()) for answer in data[\"answers\"][\"text\"]]\n",
    "    )\n",
    "    if os.environ.get(\"MAX_LEN\") != None:\n",
    "        answer_len = int(os.environ[\"MAX_LEN\"])\n",
    "\n",
    "    answer_len = 20\n",
    "\n",
    "    # Inference\n",
    "    output = model.generate(\n",
    "        input_ids = torch.tensor([text_token[\"input_ids\"]]).to(device),\n",
    "        attention_mask = torch.tensor([text_token[\"attention_mask\"]]).to(\n",
    "            device=0, dtype=torch.bfloat16\n",
    "        ),\n",
    "        max_new_tokens=answer_len,\n",
    "        pad_token_id=50277,\n",
    "    )\n",
    "    output = tokenizer.decode(output[0])\n",
    "    output = output[len(prompt) :]\n",
    "    output = output.replace(\"<|endofchunk|>\", \"\")\n",
    "    output = dataset.postprocess_vqa_generation(output)\n",
    "    output = dataset.normalize(output)\n",
    "\n",
    "    # Put together predictions\n",
    "    predictions.append({\"prediction_text\": output, \"id\": data[\"id\"]})\n",
    "    references.append({\"answers\": data[\"answers\"], \"id\": data[\"id\"]})\n",
    "\n",
    "with open(output_dir + \"squad_resutls.json\", \"w\") as f:\n",
    "    f.write(json.dumps(predictions, indent=4))\n",
    "with open(output_dir + \"squad_references.json\", \"w\") as f:\n",
    "    f.write(json.dumps(references, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exact_match': 20.85, 'f1': 35.68241137623221}\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "\n",
    "with open(f\"{output_dir}squad_resutls.json\", \"r\") as f:\n",
    "    predictions = json.load(f)\n",
    "with open(f\"{output_dir}squad_references.json\", \"r\") as f:\n",
    "    references = json.load(f)\n",
    "\n",
    "squad_metric = load(\"squad\")\n",
    "results = squad_metric.compute(predictions=predictions, references=references)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM54bAGKZSCRsGZFzoZooFW",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0ba9a4dbc6ba4d9ba3bce384b0b5a961": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1de63947f83a451dabf1adabad521adc",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_916ab2875bfe4e15983050577d352ec7",
      "value": " 4.19G/4.19G [00:19&lt;00:00, 256MB/s]"
     }
    },
    "1224601271884f2a9260fe2349df9c01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1a45a399dbe841949075e76ba5048ef6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1a5e7bd931254f68909f2c814ec9c073": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be7df70169ba4075a1ba5b1c3a7a6d01",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_ed3446b86bce4869bfc685ae58266d70",
      "value": "checkpoint.pt: 100%"
     }
    },
    "1de63947f83a451dabf1adabad521adc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23dbc31b57c6492a8b074bc8119cddf4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35ea935c05344c43b706e632c557008c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "498b93ad93c14ef39aa402e52deefd7a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62de1c57a73f4a5789da8c1c42a0c340": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1a5e7bd931254f68909f2c814ec9c073",
       "IPY_MODEL_ce63ba97e19e4ae9ae3ff9fbbb0c42c8",
       "IPY_MODEL_9339a61d8f374501866829e8593c0dee"
      ],
      "layout": "IPY_MODEL_23dbc31b57c6492a8b074bc8119cddf4"
     }
    },
    "6e5f9405d61c46349e12d5f8474b42fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "738aaf1e288542ecbd2df9c5b7b73f1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7a1d5e37d95c4026964d4ca2b19ae524": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f079869bb8f482b8dc33a32e05a300b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_89ee76fa71644ef48aa3f42e6279abfb",
       "IPY_MODEL_88001ba471f14d848f9c29d9861a07d6",
       "IPY_MODEL_0ba9a4dbc6ba4d9ba3bce384b0b5a961"
      ],
      "layout": "IPY_MODEL_c823ba48620642608a2e1cb794e7db70"
     }
    },
    "88001ba471f14d848f9c29d9861a07d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0878437ef2b41c59a91bed94bcffc98",
      "max": 4188086933,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_35ea935c05344c43b706e632c557008c",
      "value": 4188086933
     }
    },
    "89ee76fa71644ef48aa3f42e6279abfb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e5f9405d61c46349e12d5f8474b42fb",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_1224601271884f2a9260fe2349df9c01",
      "value": "checkpoint.pt: 100%"
     }
    },
    "916ab2875bfe4e15983050577d352ec7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9339a61d8f374501866829e8593c0dee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a1d5e37d95c4026964d4ca2b19ae524",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_738aaf1e288542ecbd2df9c5b7b73f1a",
      "value": " 4.19G/4.19G [00:30&lt;00:00, 241MB/s]"
     }
    },
    "be7df70169ba4075a1ba5b1c3a7a6d01": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c823ba48620642608a2e1cb794e7db70": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce63ba97e19e4ae9ae3ff9fbbb0c42c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_498b93ad93c14ef39aa402e52deefd7a",
      "max": 4188086933,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1a45a399dbe841949075e76ba5048ef6",
      "value": 4188086933
     }
    },
    "e0878437ef2b41c59a91bed94bcffc98": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed3446b86bce4869bfc685ae58266d70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
