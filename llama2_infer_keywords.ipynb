{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import transformers\n",
    "import torch\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "#notebook_login()\n",
    "API_TOKEN = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8ea6c419db74f27b1110b55d8d25562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", cache_dir=\"/mnt/d/models/\", device_map='auto', torch_dtype=torch.float16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", cache_dir=\"/mnt/d/models/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.datasets import SQUAD_dataset\n",
    "\n",
    "data = SQUAD_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = '''\n",
    "Suppose you are teaching a first grader. Answer the question accordingly and extract 10 keywords from the given context that help answer the question. The keywords need to be descriptive, and the first grader can draw a picture with them. Answer in the format \"Answer: <text>\\nKeywords: <word1>; <word2>; <word3> ...\" \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/mnt/d/datasets/psuedo_dataset.json', 'r') as f:\n",
    "    samples = json.load(f)\n",
    "\n",
    "with open('/mnt/d/datasets/image_prompts.json', 'r') as f:\n",
    "    results = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1974/1974 [00:00<00:00, 1806579.99it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "def prompt_template(context, question):\n",
    "    return instruction + f\"Question: {question}\\n Context: {context}\"\n",
    "\n",
    "for key in tqdm.tqdm(samples.keys()):\n",
    "    torch.cuda.empty_cache()\n",
    "    if results.get(key):\n",
    "        continue\n",
    "\n",
    "    idx = data.train_dataset['id'].index(key)\n",
    "    sample = data.train_dataset[idx]\n",
    "    context = sample['context']\n",
    "    id = sample['id']\n",
    "    question = sample['question']\n",
    "    input = prompt_template(context, question)\n",
    "    encoded = tokenizer(input, return_tensors='pt')\n",
    "    output = model.generate(\n",
    "        input_ids = encoded['input_ids'].to(0),\n",
    "        attention_mask = encoded['attention_mask'].to(0, dtype=torch.float16),\n",
    "        max_new_tokens = 500\n",
    "        )\n",
    "    answer = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    #print(answer)\n",
    "    try:\n",
    "        final = answer.split('Keywords:')[2]\n",
    "    except:\n",
    "        final = ''\n",
    "    #final = \";\".join(answer.split(\"Keywords:\")[2].split(\",\")[:10])\n",
    "    results[id] = final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/mnt/d/datasets/image_prompts.json', 'w') as f:\n",
    "    json.dump(results, f, indent=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flamingo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
